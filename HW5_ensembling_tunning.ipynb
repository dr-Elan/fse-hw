{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5 ENSEMBLING, TUNNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyUMcokLt7u9"
   },
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9iVG2EDt7u-"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install lightgbm==3.0\n",
    "!pip install gdown\n",
    "!pip install optuna\n",
    "!pip install catboost\n",
    "!pip install pytorch-tabnet\n",
    "!pip install -U imbalanced-learn\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fVvqxbMQt7u_"
   },
   "outputs": [],
   "source": [
    "import catboost\n",
    "import itertools\n",
    "import imblearn\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import xgboost\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, VotingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV, cross_validate, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, balanced_accuracy_score, average_precision_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from pytorch_tabnet.tab_model import  TabNetRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8zf9cmBt7vB"
   },
   "source": [
    "Функция для визуализации результата (можете модифицировать).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GmD6oXo7t7vB"
   },
   "outputs": [],
   "source": [
    "def plot_regression_predictions(tree_reg, x, y, max_depth, x_range = [0, 1],\n",
    "                                y_range = [-1, 1]):\n",
    "    \"\"\"\n",
    "    Visualize data and model predictions\n",
    "    :param tree_reg: trained model,\n",
    "    :param x: features\n",
    "    :param y: true values\n",
    "    :param max_depth: max tree depth\n",
    "    :param x_range: x range\n",
    "    :param y_range: y range\n",
    "    \"\"\"\n",
    "    x_pred = np.linspace(x_range[0], x_range[1], 500).reshape(-1, 1)\n",
    "    y_pred = tree_reg.predict(x_pred)\n",
    "\n",
    "    plt.xlim(x_range)\n",
    "    plt.ylim(y_range)\n",
    "\n",
    "    plt.xlabel(\"$x$\", fontsize=18)\n",
    "    plt.ylabel(\"$y$\", fontsize=18, rotation=0)\n",
    "\n",
    "    plt.plot(x, y, \"b.\", label=\"data\")\n",
    "    plt.plot(x_pred, y_pred, \"r.-\", linewidth=2, label=f\"max_depth = {max_depth}\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLxThDv1t7vC"
   },
   "source": [
    "Продемонстрируйте результат [`DecisionTreeRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) при изменении глубины дерева (`random_state=42`). Попробуйте значения глубины $2, 5, 6, 9, 12, 15$\n",
    "Используйте для визуализации те же данные, на которых происходило обучение.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILCusf7ut7vC"
   },
   "source": [
    "Примечание: Для построения серии картинок используйте `plt.subplot`.\n",
    "Пример использования: [ссылка](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/shared_axis_demo.html#sphx-glr-gallery-subplots-axes-and-figures-shared-axis-demo-py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7ybGDxjt7vD"
   },
   "source": [
    "# Задание 1. Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOsT5kjRt7vD"
   },
   "source": [
    "В этом задании используйте датасет breast_cancer &mdash; классический датасет для задачи бинарной классификации. Обучите модели:\n",
    "\n",
    " - `DecisionTreeClassifier`\n",
    " -`RandomForestClassifier`\n",
    " -`LigthGBMClassifier`\n",
    " -`SVC`\n",
    " -`BaggingClassifier` с базовым класификатором - SVC .\n",
    "\n",
    "Параметры моделей можете оставить по умолчанию или задать сами.\n",
    "\n",
    "Для каждой модели посчитайте [корреляцию Мэтьюса](https://en.wikipedia.org/wiki/Phi_coefficient) &mdash; метрику для оценки качества бинарной классификации, в частности, устойчивую к дисбалансу классов, ([`sklearn.metrics.matthews_corrcoef`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html), подробнее почитать про его пользу можно [здесь](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7)) для предсказанного ею класса и реального\n",
    "\n",
    "С помощью bootstrap-подхода постройте 90% доверительные интервалы для качества полученных моделей. Используйте функцию `bootstrap_metric` из лекции ().\n",
    "\n",
    "Постройте [боксплоты](https://seaborn.pydata.org/generated/seaborn.boxplot.html) для качества полученных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5MxDjBybt7vD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "breast_cancer = sklearn.datasets.load_breast_cancer()\n",
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-7DLsDwt7vD"
   },
   "outputs": [],
   "source": [
    "x = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1YhdZYeRt7vE"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B82oli85t7vE"
   },
   "source": [
    "Сделайте вывод о том, какие модели работают лучше.\n",
    "\n",
    "**Напишите вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQWdwPL4t7vE"
   },
   "source": [
    "## Формат результата"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsCaJahmt7vE"
   },
   "source": [
    "График с демонстрацией корреляции Мэтьюса для следующих моделей:\n",
    "\n",
    " - `DecisionTreeClassifier`\n",
    " -`RandomForestClassifier`\n",
    " -`LigthGBMClassifier`\n",
    " -`SVC`\n",
    " -`BaggingClassifier` с базовым класификатором - SVC .\n",
    "\n",
    "\n",
    "Пример графика:\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/Exercises/EX03/result_2_task_ex03.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "899PDVYLt7vE"
   },
   "source": [
    "# Задание 2. Обучение и подбор параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwqxVFyCt7vE"
   },
   "source": [
    "Загрузим датасет с рецептами (состав блюд и дополнительные данные о них) и рейтинге рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XyEEIDBSt7vF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calories  protein   fat  sodium  cakeweek\n",
      "0     426.0     30.0   7.0   559.0       0.0\n",
      "1     403.0     18.0  23.0  1439.0       0.0\n",
      "2     165.0      6.0   7.0   165.0       0.0\n",
      "3     547.0     20.0  32.0   452.0       0.0\n",
      "4     948.0     19.0  79.0  1042.0       0.0\n"
     ]
    }
   ],
   "source": [
    "recipies = pd.read_csv(\"data/recipes.csv\")\n",
    "print(recipies.iloc[:, 0:5].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNVuQ6Ent7vF"
   },
   "outputs": [],
   "source": [
    "recipies = recipies.loc[pd.isna(recipies).sum(axis=1)==0, :] # remove na\n",
    "y = recipies['rating']\n",
    "x = recipies.drop([\"rating\", \"title\"], axis=1)\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(x.values, y.values, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBtTA12ot7vF"
   },
   "source": [
    "Постройте модель, предсказывающую рейтинг рецепта по всем имеющимся признакам. Для анализа качества моделей используйте метрику `MSE`.\n",
    "\n",
    "Выберите 2 модели &mdash; один случайный лес и один бустинг из приведенных ниже.\n",
    "\n",
    "1. `xgboost.XGBRegressor`\n",
    "2. `xgboost.XGBRFRegressor` (случайный лес от xgboost)\n",
    "3. `lightgbm.LGBMRegressor`\n",
    "4. `lightgbm.LGBMRegressor(boosting_type=\"rf\")` (случайный лес от lightgbm)\n",
    "5. `catboost.CatBoostRegressor`\n",
    "\n",
    "Кроме этого, используйте так же\n",
    "`TabNetRegressor`. Установите число эпох (`max_epochs`, параметр функции `fit`) равным 30.\n",
    "\n",
    "Для первых двух моделей попытайтесь оптимизировать их параметры, чтобы получить хорошее качество.\n",
    "\n",
    "Сравните качество полученных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MlCcxVVt7vF"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdrWJiBit7vF"
   },
   "source": [
    "Сравните качество моделей с гиперпараметрами, подобранными вручную и бустинга `LightGBM` с гиперпараметрами, оптимизированными автоматически с помощью фреймворка [`optuna`](https://optuna.org/).\n",
    "\n",
    "`optuna` используется для подбора гиперпараметров различных моделей машинного обучения и встретится в этом курсе ещё неоднократно. В частности для оптимизации градиентного бустинга `LightGBM` используется функция `optuna.integration.lightgbm.LightGBMTunerCV`. Другие функции можно найти по [ссылке](https://optuna.readthedocs.io/en/stable/reference/integration.html).\n",
    "\n",
    "Используйте параметры, полученные при оптимизации модели с помошью `optuna.integration.lightgbm.LightGBMTunerCV` для обучения модели `LightGBM`.\n",
    "\n",
    "Сравните качество полученных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkBKlL_Ht7vF"
   },
   "outputs": [],
   "source": [
    "?optuna.integration.lightgbm.LightGBMTunerCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-CZKvott7vG"
   },
   "outputs": [],
   "source": [
    "dtrain = optuna.integration.lightgbm.Dataset(x_train_all, label=y_train_all)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\"}\n",
    "\n",
    "tuner = optuna.integration.lightgbm.LightGBMTunerCV(params=params,\n",
    "                                                    train_set=dtrain,\n",
    "                                                    verbose_eval=False,\n",
    "                                                    early_stopping_rounds=100,\n",
    "                                                    time_budget=600,\n",
    "                                                    folds=KFold(n_splits=4, shuffle=True),\n",
    "                                                    seed=42)\n",
    "\n",
    "tuner.run()\n",
    "\n",
    "print(\"\\nBest score:\", tuner.best_score)\n",
    "best_params = tuner.best_params\n",
    "print(\"\\nBest parameters: \")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YdJ5Qu9mt7vG"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_yGVJ0Ut7vG"
   },
   "source": [
    "## Формат результата"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8tp9OLzt7vG"
   },
   "source": [
    "Получить значения MSE для моделей:\n",
    "\n",
    "1. Случайный лес ~ 1.4\n",
    "2. Бустинг меньше 1.45\n",
    "3. TabNet ~ 1.5\n",
    "4. С использованием optuna ~ 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjtIbTbct7vG"
   },
   "source": [
    "# Задание 3. Дисбаланс классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuMbkeADt7vG"
   },
   "source": [
    "Важно обращать внимание на сбалансированность классов в наборе.\n",
    "Предположим, у нас есть некоторый набор данных со следующими метками классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJS7cYoyt7vH"
   },
   "outputs": [],
   "source": [
    "real_labels  = [1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjIe7A16t7vH"
   },
   "source": [
    "В наборе 16 объектов относятся к классу 0, 5 к классу 1.\n",
    "\n",
    "Мы обучили две модели. Первая всегда выдает 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UuZcBziEt7vH"
   },
   "outputs": [],
   "source": [
    "model1_res = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XY0f67Nt7vH"
   },
   "source": [
    "Вторая сумела обнаружить некоторую закономерность в признаках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMV-U2Ult7vH"
   },
   "outputs": [],
   "source": [
    "model2_res = [1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVwRj64Ut7vH"
   },
   "source": [
    "Рассчитаем точность Accuracy для этих моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rxFe9o_t7vH"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy for model1: \", accuracy_score(real_labels, model1_res))\n",
    "print(\"Accuracy for model2: \", accuracy_score(real_labels, model2_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzsuwW2Jt7vH"
   },
   "source": [
    "Accuracy нельзя использовать, если данные не сбалансированы!!!. Для несбалансированных данных необходимо использовать свои метрики и модели. Одной из таких метрик является balanced accuracy. При вычислении данной метрики считается полнота (recall) отдельно для каждого класса и вычисляется среднее значение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypsmtSFyt7vI"
   },
   "outputs": [],
   "source": [
    "# Balanced accuracy for model1 = (16/16+0/5)/2 = 0.5\n",
    "print(\"Balanced accuracy for model1: \", balanced_accuracy_score(real_labels, model1_res))\n",
    "# Balanced accuracy for model2 = (12/16+4/5)/2 = 0.775\n",
    "print(\"Balanced accuracy for model2: \", balanced_accuracy_score(real_labels, model2_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVCgh14-t7vI"
   },
   "source": [
    "**Всегда проверяйте** являются ли ваши данные сбалансированными и могут ли выбранные для оценки модели метрики работать с несбалансированными классами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxpRJVLtt7vI"
   },
   "source": [
    "Загрузим датасет с различными биомаркерами пациентов с меланомой (обезличенный, информации о пациентах нет) и переменной, содержащей 1, если пациент ответил на иммунотерапию (терапия помогла пациенту и произошло уменьшение размеров опухоли) и 0, если не ответил. Количество пациентов, отвечающих на терапию сильно меньше пациентов, которым терапия не помогает, поэтому предсказание ответа пациента на терапию на основании биомаркеров &mdash; актуальная задача в онкологии. В данном задании вам предстоит попробовать её решить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oTgEPp-Pt7vI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IgG1/IgA</th>\n",
       "      <th>IL21</th>\n",
       "      <th>CXCL9</th>\n",
       "      <th>CXCL10</th>\n",
       "      <th>CD8A</th>\n",
       "      <th>GZMB</th>\n",
       "      <th>KLRC2</th>\n",
       "      <th>KLRC3</th>\n",
       "      <th>KLRC4</th>\n",
       "      <th>GNLY</th>\n",
       "      <th>TGFB1</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SAM4b0175e8db6e</th>\n",
       "      <td>3.242746</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>-0.002986</td>\n",
       "      <td>-0.036366</td>\n",
       "      <td>0.096658</td>\n",
       "      <td>0.063467</td>\n",
       "      <td>0.502058</td>\n",
       "      <td>-0.083862</td>\n",
       "      <td>0.053659</td>\n",
       "      <td>0.091930</td>\n",
       "      <td>61.934119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMd215b503f99a</th>\n",
       "      <td>2.139016</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>0.030495</td>\n",
       "      <td>0.243958</td>\n",
       "      <td>0.161128</td>\n",
       "      <td>0.565798</td>\n",
       "      <td>-0.203495</td>\n",
       "      <td>-0.026902</td>\n",
       "      <td>-0.035405</td>\n",
       "      <td>0.030125</td>\n",
       "      <td>103.265837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAM7fb6987514a4</th>\n",
       "      <td>12.614972</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>0.502043</td>\n",
       "      <td>0.530783</td>\n",
       "      <td>0.388455</td>\n",
       "      <td>0.528142</td>\n",
       "      <td>-0.156209</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>-0.028690</td>\n",
       "      <td>0.260703</td>\n",
       "      <td>53.552817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMd636e3461955</th>\n",
       "      <td>6.365973</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>0.024035</td>\n",
       "      <td>0.115127</td>\n",
       "      <td>0.084455</td>\n",
       "      <td>0.200038</td>\n",
       "      <td>-0.387373</td>\n",
       "      <td>-0.057837</td>\n",
       "      <td>0.045938</td>\n",
       "      <td>0.073192</td>\n",
       "      <td>80.837318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMc0da5d48686d</th>\n",
       "      <td>2.764089</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>0.135470</td>\n",
       "      <td>0.067686</td>\n",
       "      <td>0.053499</td>\n",
       "      <td>-0.116040</td>\n",
       "      <td>0.063714</td>\n",
       "      <td>0.088201</td>\n",
       "      <td>0.082940</td>\n",
       "      <td>114.422926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  IgG1/IgA      IL21     CXCL9    CXCL10      CD8A      GZMB  \\\n",
       "sample_id                                                                      \n",
       "SAM4b0175e8db6e   3.242746  0.001280 -0.002986 -0.036366  0.096658  0.063467   \n",
       "SAMd215b503f99a   2.139016 -0.000089  0.030495  0.243958  0.161128  0.565798   \n",
       "SAM7fb6987514a4  12.614972  0.008103  0.502043  0.530783  0.388455  0.528142   \n",
       "SAMd636e3461955   6.365973 -0.000139  0.024035  0.115127  0.084455  0.200038   \n",
       "SAMc0da5d48686d   2.764089  0.006107  0.015533  0.135470  0.067686  0.053499   \n",
       "\n",
       "                    KLRC2     KLRC3     KLRC4      GNLY       TGFB1  Response  \n",
       "sample_id                                                                      \n",
       "SAM4b0175e8db6e  0.502058 -0.083862  0.053659  0.091930   61.934119         0  \n",
       "SAMd215b503f99a -0.203495 -0.026902 -0.035405  0.030125  103.265837         0  \n",
       "SAM7fb6987514a4 -0.156209  0.001147 -0.028690  0.260703   53.552817         0  \n",
       "SAMd636e3461955 -0.387373 -0.057837  0.045938  0.073192   80.837318         0  \n",
       "SAMc0da5d48686d -0.116040  0.063714  0.088201  0.082940  114.422926         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of patients responded to immunotherapy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    228\n",
       "1     37\n",
       "Name: Response, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cancer = pd.read_table(\"data/Cancer_dataset_2.tsv\", index_col='sample_id')\n",
    "display(cancer.head())\n",
    "\n",
    "# split the data on features (x) and dependant variable (y)\n",
    "y = cancer['Response']\n",
    "x = cancer.drop('Response', axis=1)\n",
    "print('\\nNumber of patients responded to immunotherapy:')\n",
    "display(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNAQEeqHt7vI"
   },
   "source": [
    "В данном случае имеет место несбалансированность классов в наборе данных: пациентов, ответивших на терапию, гораздо меньше.\n",
    "\n",
    "Есть два способа работы с несбалансированными по классам данными. Первый способ &mdash; это получение стратифицированных выборок. Необходимо иметь одинаковую долю образцов каждого класса в тренировочной и тестовой выборках, иначе возникает риск получения смещённых выборок, что приводит к некорректной оценке качества модели. Второй способ &mdash; это использование специальных алгоритмов, учитывающих несбалансированность классов.\n",
    "\n",
    "\n",
    "В данном задании вам нужно продемонстрировать эффективность различных подходов  работы с несбалансированными выборками. Для этого вы будете использовать три модели, представленные ниже:\n",
    "\n",
    "1. [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), библиотека sklearn\n",
    "2. [`RandomForestClassifier` с балансировкой классов](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), библиотека sklearn  - меняет стандартный вес каждого класса, равный 1, на долю класса во входных данных (см. `class_weight`).\n",
    "3. [`BalancedRandomForestClassifier`](https://imbalanced-learn.org/stable/references/generated/imblearn.ensemble.BalancedRandomForestClassifier.html), библиотека imblearn - сэмплирует псевдовыборки таким образом, что в каждой псевдовыборке, которая подается на вход модели, баланс классов оказывается \"выправлен\".\n",
    "\n",
    "Оцените эффективность подходов с помощью кросс-валидации, производя разбиение с учетом репрезентации классов и без него. В качестве метрики, отображающей эффективность модели, используйте значения `accuracy` и `balanced_accuracy`. Проинтерпретируйте результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMmPwWh1t7vI"
   },
   "outputs": [],
   "source": [
    "?imblearn.ensemble.BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-hmV1axt7vI"
   },
   "outputs": [],
   "source": [
    "?cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2s-R4k6at7vJ"
   },
   "source": [
    "Объекты, принадлежащие разным классам, распределены неравномерно. Для адекватной работы cross_validate нужно перемешать данные. Для этого используйте флаг shuffle=True, применяя `KFold` и `StratifiedKFold` (см. параметр `cv` в функции cross_validate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yo02aKd3t7vJ"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nF_yQx1Jt7vJ"
   },
   "source": [
    "Какая модель лучше справляется с дисбалансом классов?\n",
    "\n",
    "**Напишите вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcMQe6Fit7vJ"
   },
   "source": [
    "## Формат результата"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaaGqItIt7vJ"
   },
   "source": [
    "Для моделей:\n",
    "1. `RandomForestClassifier`, библиотека sklearn\n",
    "2. `RandomForestClassifier с балансировкой классов`, библиотека sklearn\n",
    "3. `BalancedRandomForestClassifier`, библиотека imblearn\n",
    "\n",
    "Получить значения `accuracy` и `balanced_accuracy` при `KFold`-кроссвалидации и `StratifiedKFold`-кроссвалидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTsFUHpjt7vJ"
   },
   "source": [
    "# Задание 4. Корреляция базовых моделей (maybe HARD - EXTRA)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GO6EgNTt7vJ"
   },
   "source": [
    "Для случайного леса, на примере датасета breast_cancer, постройте зависимость между попарными корреляциями базовых моделей и числом фичей, которые отбираются в каждую модель.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0Ei_B_qt7vK"
   },
   "outputs": [],
   "source": [
    "breast_cancer = sklearn.datasets.load_breast_cancer()\n",
    "\n",
    "x = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRe1v5sLt7vK"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bM4llEHmt7vK"
   },
   "source": [
    "В параграфе лекции **Метод случайных подпространств** дана информация о рекомендованном количестве признаков для задачи классификации. Как соотносится полученный график и рекомендуемое количество признаков?\n",
    "\n",
    "**Напишите вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTAdQamEt7vK"
   },
   "source": [
    "## Формат результата"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxbV8gXnt7vK"
   },
   "source": [
    "График зависимости между попарными корреляциями базовых моделей и числом фичей, которые отбираются в каждую модель.\n",
    "\n",
    "Пример графика:\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/Exercises/EX03/result_5_task_ex03.png\" width=\"600\">"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

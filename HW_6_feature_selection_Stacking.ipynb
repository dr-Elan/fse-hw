{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW6 BOOSTING, STACKING, BLENDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyUMcokLt7u9"
   },
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9iVG2EDt7u-"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install lightgbm==3.0\n",
    "!pip install gdown\n",
    "!pip install optuna\n",
    "!pip install catboost\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fVvqxbMQt7u_"
   },
   "outputs": [],
   "source": [
    "import catboost\n",
    "import itertools\n",
    "import imblearn\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import xgboost\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, VotingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV, cross_validate, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, balanced_accuracy_score, average_precision_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5JcxVPVXLwU"
   },
   "source": [
    "# Задание 1. Feature selection и feature engineering\n",
    "\n",
    "В этом задании используя датасет с [данными о здоровье плода](https://www.kaggle.com/andrewmvd/fetal-health-classification), сравните различные подходы к отбору признаков. Загрузим датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/fetal_health.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на данные. Видно, что среди представленных признаков довольно много скоррелированных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('fetal_health', axis=1)\n",
    "x = pd.DataFrame(StandardScaler().fit_transform(x), columns=x.columns, index= x.index)\n",
    "y = data['fetal_health']\n",
    "\n",
    "corr_matrix = x.corr(method='spearman')\n",
    "res = sns.clustermap(corr_matrix, method='weighted', figsize=(10, 10), cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя жадный отбор признаков, Add Del и PCA, отберите/сгенерируйте от 1 до 20 признаков и сравните на кросс-валидации accuracy для моделей RandomForestClassifier(n_estimators=50, random_state=42) из sklearn.ensemble, получающихся в процессе отбора/генерации признаков. Сравните полученные результаты с accuracy модели, обученной с использованием всех имеющихся признаков (на кросс-валидации с тем же количеством фолдов). Изобразите результаты в виде графика, опишите свои наблюдения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## ENTER YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mh1OHP1kXLwW"
   },
   "source": [
    "_Вывод:_\n",
    "\n",
    "_Ваш текст тут._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyF6GJHJXLwX"
   },
   "source": [
    "## Формат результата\n",
    "\n",
    "* Accuracy модели, обученной с использованием всех имеющихся признаков >0.9.\n",
    "\n",
    "* Пример графика для одного из пунктов задания:\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/Exercises/EX04/result_3_task_ex04_fix.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWrHqVSTt7vK"
   },
   "source": [
    "# Задание 2. Ансамблевое обучение *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX0NKw7ot7vL"
   },
   "source": [
    "В данной задаче вам нужно диагностировать сердечное заболевание у людей по [медицинским показателям](https://www.kaggle.com/datasets/cherngs/heart-disease-cleveland-uci)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KQ6alM-ct7vL"
   },
   "outputs": [],
   "source": [
    "heart_dataset = pd.read_csv(\"data/heart.csv \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g05CK4_4t7vL"
   },
   "outputs": [],
   "source": [
    "x = heart_dataset.drop(\"target\", axis=1)\n",
    "y = heart_dataset['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTPtnCJYt7vL"
   },
   "source": [
    "Обучите разнообразные классификаторы, приведенные ниже, а также ансамбль `VotingClassifier` из `sklearn.ensemble`, объединяющий эти классификаторы с помощью жесткого или мякого голосования (параметр `voting =` `'hard'` или `'soft'` соответственно). Оцените качество моделей с помощью кросс-валидации на тренировочном наборе, используя функцию `cross_val_score` и метрику `f1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tW4UpIst7vL"
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=rng, max_depth=10, min_samples_leaf=10)\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=rng)\n",
    "etc = ExtraTreesClassifier(random_state=rng)\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "svc_lin = SVC(kernel='linear', probability=True, random_state=rng)\n",
    "svc_rbf = SVC(kernel='rbf', probability=True, random_state=rng)\n",
    "cat = catboost.CatBoostClassifier(verbose=0, random_seed=42)\n",
    "lgbm = lightgbm.LGBMClassifier(random_state=42)\n",
    "lgbm_rf = lightgbm.LGBMClassifier(boosting_type=\"rf\", bagging_freq=1, bagging_fraction=0.7, random_state=42)\n",
    "xgb = xgboost.XGBClassifier(random_state=42)\n",
    "xgb_rf = xgboost.XGBRFClassifier(random_state=42)\n",
    "lr = LogisticRegression(solver='liblinear', max_iter=10000)\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Your code here\n",
    "\n",
    "voting_hard =\n",
    "voting_soft =\n",
    "# -----------\n",
    "\n",
    "for model in [dt, rf, cat, etc, knn, svc_lin, svc_rbf,  xgb, lgbm,  xgb_rf, lgbm_rf, lr, nb, voting_hard, voting_soft]:\n",
    "    scores = cross_val_score(model, x_train, y_train, cv=KFold(n_splits=3, shuffle=True, random_state=rng), scoring='f1')\n",
    "    print(f'{model.__class__.__name__}: {scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdXmwVZ-t7vL"
   },
   "source": [
    "Вы можете заметить, что ансамбль показывает хорошее, но не лучшее качество предсказания, попробуем его улучшить. Как вы знаете, ансамбли работают лучше, когда модели, входящие в них не сккоррелированы друг с другом. Определите корреляцию предсказаний базовых моделей в ансамбле на тренировочном наборе, и удалите из ансамбля те модели, чьи предсказания будут сильнее коррелировать с остальными. Можете модифицировать функцию `base_model_pair_correlation` из предыдущего задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AADDFu6dt7vL"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRI1Ur1Wt7vM"
   },
   "source": [
    "Создайте новый ансамбль, на исправленном наборе моделей и оцените его качество с помощью кросс-валидации на тренировочном наборе, используя функцию `cross_val_score` и метрику `f1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "haX2TGcmt7vM"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "voting_hard_2 =\n",
    "voting_soft_2 =\n",
    "# ------------\n",
    "\n",
    "for model in [voting_hard_2, voting_soft_2]:\n",
    "    scores = cross_val_score(model, x_train, y_train, cv=KFold(n_splits=3, shuffle=True, random_state=rng), scoring='f1')\n",
    "    print(f'{model.__class__.__name__}: {scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCHdnHKXt7vM"
   },
   "source": [
    "Обучите все получившиеся модели на тренировочном наборе и испытайте их качество на тестовом наборе. Получилось ли у улучшенных версий ансамблевого классификатора превзойти базовые модели, входящие в него и свои предыдущие версии?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0j2MUQwit7vM"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFnnbxipt7vM"
   },
   "source": [
    "Какие ансамбли работают лучше? Всегда ли больше моделей значит лучше?\n",
    "\n",
    "**Напишите вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZ5aydTMt7vM"
   },
   "source": [
    "## Формат результата"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFu6a-pMt7vM"
   },
   "source": [
    "Получить значения качества для ансамблей и моделей."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
